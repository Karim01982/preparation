---
title: "What makes a Hollywood film successful?"
author: Joanna Andari, Karim Awad, Jiye Ren, Nirbhay Sharma, Qiuyue Zhang, Xiaoyan
  Zhou
date: "13 October 2017"
output:
  html_document:
    toc: TRUE
  pdf_document: default
---
<style>
table, td, th {
  border: 1pt;
  padding-left: 1em;
  padding-right: 1em;
  min-width: 50%;
  margin-left: auto;
  margin-right: auto;
  margin-top: 1em;
  margin-bottom: 1em;
}
</style>

```{r, echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
library(stargazer)
library(car)
library(dplyr)
library(readr)
library(tidyr)
library(magrittr)
library(stringr)
library(ggplot2)
library(knitr)
library(gridExtra)
library(psych)

```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
##Initial cleaning
old_data <- read.csv("./movie_metadata.csv", stringsAsFactors = FALSE)

film_country <- old_data %>%
  group_by(country) %>%
  summarise(n=n())

filter_data <- filter(old_data, country=="USA", language=="English")
select_data <- select(filter_data, movie_title, title_year, director_name, duration, gross, genres, num_voted_users, num_user_for_reviews, budget, imdb_score, movie_facebook_likes, actor_1_name, actor_2_name, actor_3_name)
select_data_filter <- filter(select_data, title_year >= 2011, gross !=0, gross != "NA", gross != "", imdb_score != 0, imdb_score != "NA", imdb_score != "", budget != 0, budget != "NA", budget != "", movie_facebook_likes != 0, movie_facebook_likes != "NA", movie_facebook_likes != "")

##Genre conversion
genre_names <- c("Action","Adventure", "Animation", "Biography", "Comedy", "Crime", "Documentary", "Drama", "Family", "Fantasy", "History", "Horror", "Musical", "Mystery", "News", "Romance", "Sci-Fi", "Sport", "Thriller", "War", "Western")
genre_types <- c("genre1", "genre2","genre3", "genre4", "genre5", "genre6", "genre7")
genre_filter <- select_data_filter %>% separate(genres, into=genre_types,sep = "\\|")

##Establishing a Gross Revenue / Budget variable and cleaning up movie title names
RB_data <- mutate(.data = genre_filter, return = gross / budget)
RB_data$return <- round(RB_data$return, 2)

##Clean RB_data of duplicates and the additional character in name
RB_data$movie_title = substr(RB_data$movie_title,1,nchar(RB_data$movie_title)-1)
RB_data <- RB_data[-c(as.vector(which(duplicated(RB_data) == TRUE))),]

##Introducing flags for genres

RB_data$actiondummy <- as.numeric( RB_data$genre1 == "Action" | RB_data$genre2 == "Action" | RB_data$genre3 == "Action" | RB_data$genre4 == "Action" | RB_data$genre5 == "Action" | RB_data$genre6 == "Action" | RB_data$genre7 == "Action")
RB_data$actiondummy[is.na(RB_data$actiondummy)] <- 0

RB_data$adventuredummy <- as.numeric( RB_data$genre1 == "Adventure" | RB_data$genre2 == "Adventure" | RB_data$genre3 == "Adventure" | RB_data$genre4 == "Adventure" | RB_data$genre5 == "Adventure" | RB_data$genre6 == "Adventure" | RB_data$genre7 == "Adventure")
RB_data$adventuredummy[is.na(RB_data$adventuredummy)] <- 0

RB_data$animationdummy <- as.numeric( RB_data$genre1 == "Animation" | RB_data$genre2 == "Animation" | RB_data$genre3 == "Animation" | RB_data$genre4 == "Animation" | RB_data$genre5 == "Animation" | RB_data$genre6 == "Animation" | RB_data$genre7 == "Animation")
RB_data$animationdummy[is.na(RB_data$animationdummy)] <- 0

RB_data$biographydummy <- as.numeric( RB_data$genre1 == "Biography" | RB_data$genre2 == "Biography" | RB_data$genre3 == "Biography" | RB_data$genre4 == "Biography" | RB_data$genre5 == "Biography" | RB_data$genre6 == "Biography" | RB_data$genre7 == "Biography")
RB_data$biographydummy[is.na(RB_data$biographydummy)] <- 0

RB_data$comedydummy <- as.numeric( RB_data$genre1 == "Comedy" | RB_data$genre2 == "Comedy" | RB_data$genre3 == "Comedy" | RB_data$genre4 == "Comedy" | RB_data$genre5 == "Comedy" | RB_data$genre6 == "Comedy" | RB_data$genre7 == "Comedy")
RB_data$comedydummy[is.na(RB_data$comedydummy)] <- 0

RB_data$crimedummy <- as.numeric( RB_data$genre1 == "Crime" | RB_data$genre2 == "Crime" | RB_data$genre3 == "Crime" | RB_data$genre4 == "Crime" | RB_data$genre5 == "Crime" | RB_data$genre6 == "Crime" | RB_data$genre7 == "Crime")
RB_data$crimedummy[is.na(RB_data$crimedummy)] <- 0

RB_data$documentarydummy <- as.numeric( RB_data$genre1 == "Documentary" | RB_data$genre2 == "Documentary" | RB_data$genre3 == "Documentary" | RB_data$genre4 == "Documentary" | RB_data$genre5 == "Documentary" | RB_data$genre6 == "Documentary" | RB_data$genre7 == "Documentary")
RB_data$documentarydummy[is.na(RB_data$documentarydummy)] <- 0

RB_data$dramadummy <- as.numeric( RB_data$genre1 == "Drama" | RB_data$genre2 == "Drama" | RB_data$genre3 == "Drama" | RB_data$genre4 == "Drama" | RB_data$genre5 == "Drama" | RB_data$genre6 == "Drama" | RB_data$genre7 == "Drama")
RB_data$dramadummy[is.na(RB_data$dramadummy)] <- 0

RB_data$familydummy <- as.numeric( RB_data$genre1 == "Family" | RB_data$genre2 == "Family" | RB_data$genre3 == "Family" | RB_data$genre4 == "Family" | RB_data$genre5 == "Family" | RB_data$genre6 == "Family" | RB_data$genre7 == "Family")
RB_data$familydummy[is.na(RB_data$familydummy)] <- 0

RB_data$fantasydummy <- as.numeric( RB_data$genre1 == "Fantasy" | RB_data$genre2 == "Fantasy" | RB_data$genre3 == "Fantasy" | RB_data$genre4 == "Fantasy" | RB_data$genre5 == "Fantasy" | RB_data$genre6 == "Fantasy" | RB_data$genre7 == "Fantasy")
RB_data$fantasydummy[is.na(RB_data$fantasydummy)] <- 0

RB_data$historydummy <- as.numeric( RB_data$genre1 == "History" | RB_data$genre2 == "History" | RB_data$genre3 == "History" | RB_data$genre4 == "History" | RB_data$genre5 == "History" | RB_data$genre6 == "History" | RB_data$genre7 == "History")
RB_data$historydummy[is.na(RB_data$historydummy)] <- 0

RB_data$horrordummy <- as.numeric( RB_data$genre1 == "Horror" | RB_data$genre2 == "Horror" | RB_data$genre3 == "Horror" | RB_data$genre4 == "Horror" | RB_data$genre5 == "Horror" | RB_data$genre6 == "Horror" | RB_data$genre7 == "Horror")
RB_data$horrordummy[is.na(RB_data$horrordummy)] <- 0

RB_data$musicaldummy <- as.numeric( RB_data$genre1 == "Musical" | RB_data$genre2 == "Musical" | RB_data$genre3 == "Musical" | RB_data$genre4 == "Musical" | RB_data$genre5 == "Musical" | RB_data$genre6 == "Musical" | RB_data$genre7 == "Musical")
RB_data$musicaldummy[is.na(RB_data$musicaldummy)] <- 0

RB_data$mysterydummy <- as.numeric( RB_data$genre1 == "Mystery" | RB_data$genre2 == "Mystery" | RB_data$genre3 == "Mystery" | RB_data$genre4 == "Mystery" | RB_data$genre5 == "Mystery" | RB_data$genre6 == "Mystery" | RB_data$genre7 == "Mystery")
RB_data$mysterydummy[is.na(RB_data$mysterydummy)] <- 0

RB_data$newsdummy <- as.numeric( RB_data$genre1 == "News" | RB_data$genre2 == "News" | RB_data$genre3 == "News" | RB_data$genre4 == "News" | RB_data$genre5 == "News" | RB_data$genre6 == "News" | RB_data$genre7 == "News")
RB_data$newsdummy[is.na(RB_data$newsdummy)] <- 0

RB_data$romancedummy <- as.numeric( RB_data$genre1 == "Romance" | RB_data$genre2 == "Romance" | RB_data$genre3 == "Romance" | RB_data$genre4 == "Romance" | RB_data$genre5 == "Romance" | RB_data$genre6 == "Romance" | RB_data$genre7 == "Romance")
RB_data$romancedummy[is.na(RB_data$romancedummy)] <- 0

RB_data$scifidummy <- as.numeric( RB_data$genre1 == "Sci-Fi" | RB_data$genre2 == "Sci-Fi" | RB_data$genre3 == "Sci-Fi" | RB_data$genre4 == "Sci-Fi" | RB_data$genre5 == "Sci-Fi" | RB_data$genre6 == "Sci-Fi" | RB_data$genre7 == "Sci-Fi")
RB_data$scifidummy[is.na(RB_data$scifidummy)] <- 0

RB_data$sportdummy <- as.numeric( RB_data$genre1 == "Sport" | RB_data$genre2 == "Sport" | RB_data$genre3 == "Sport" | RB_data$genre4 == "Sport" | RB_data$genre5 == "Sport" | RB_data$genre6 == "Sport" | RB_data$genre7 == "Sport")
RB_data$sportdummy[is.na(RB_data$sportdummy)] <- 0

RB_data$thrillerdummy <- as.numeric( RB_data$genre1 == "Thriller" | RB_data$genre2 == "Thriller" | RB_data$genre3 == "Thriller" | RB_data$genre4 == "Thriller" | RB_data$genre5 == "Thriller" | RB_data$genre6 == "Thriller" | RB_data$genre7 == "Thriller")
RB_data$thrillerdummy[is.na(RB_data$thrillerdummy)] <- 0

RB_data$wardummy <- as.numeric( RB_data$genre1 == "War" | RB_data$genre2 == "War" | RB_data$genre3 == "War" | RB_data$genre4 == "War" | RB_data$genre5 == "War" | RB_data$genre6 == "War" | RB_data$genre7 == "War")
RB_data$wardummy[is.na(RB_data$wardummy)] <- 0

RB_data$westerndummy <- as.numeric( RB_data$genre1 == "Western" | RB_data$genre2 == "Western" | RB_data$genre3 == "Western" | RB_data$genre4 == "Western" | RB_data$genre5 == "Western" | RB_data$genre6 == "Western" | RB_data$genre7 == "Western")
RB_data$westerndummy[is.na(RB_data$westerndummy)] <- 0

##cleaning awards data 
awards_data <- read.csv("./awards_metadata.csv", stringsAsFactors = FALSE, encoding = "UTF-8")
awards_data <- filter(awards_data, Winner!="NA")
awards_data <- select(awards_data, Year, Award, Name, Film)
movie_wins <- filter(awards_data, Award=="Best Picture" | Award=="Best Motion Picture")
movie_wins <- count(movie_wins, Name)
actor_wins <- filter(awards_data, Award=="Actor" | Award=="Actress" | Award=="Actor in a Leading Role" | Award=="Actress in a Leading Role" | Award=="Actor in a Supporting Role" | Award=="Actress in a Supporting Role")
actor_wins <- count(actor_wins, Name)
director_wins <- filter(awards_data, Award=="Directing")
director_wins$Name = director_wins$Film
director_wins <- count(director_wins, Name)
award_wins <- rbind(actor_wins,director_wins,movie_wins)

##Getting the occurences of directors/actors in the database
for (i in (1:length(RB_data))){
  RB_data$director_occurence[i] = length(which((str_detect(RB_data$director_name, RB_data$director_name[i])) == TRUE))
  RB_data$actor1_occurence[i] = length(which((str_detect(cbind(RB_data$actor_1_name, RB_data$actor_2_name, RB_data$actor_3_name),
                                                         RB_data$actor_1_name[i])) == TRUE))
  RB_data$actor2_occurence[i] = length(which((str_detect(cbind(RB_data$actor_1_name, RB_data$actor_2_name, RB_data$actor_3_name),
                                                         RB_data$actor_2_name[i])) == TRUE))
  RB_data$actor3_occurence[i] = length(which((str_detect(cbind(RB_data$actor_1_name, RB_data$actor_2_name, RB_data$actor_3_name),
                                                         RB_data$actor_3_name[i])) == TRUE))
  RB_data$sum_actor_occurence[i] = RB_data$actor1_occurence[i] + RB_data$actor2_occurence[i] + RB_data$actor3_occurence[i]
}

#FOR GETTING AWARDS DATA
occurences = table(unlist(award_wins$Name))
occurences = as.data.frame(occurences)
RB_data = left_join(x=RB_data, y=occurences, by=c(director_name = "Var1"))
colnames(RB_data)[48] <- "dir_oscars"
RB_data = left_join(x=RB_data, y=occurences, by=c(actor_1_name = "Var1"))
colnames(RB_data)[49] <- "act1_oscars"
RB_data = left_join(x=RB_data, y=occurences, by=c(actor_2_name = "Var1"))
colnames(RB_data)[50] <- "act2_oscars"
RB_data = left_join(x=RB_data, y=occurences, by=c(actor_3_name = "Var1"))
colnames(RB_data)[51] <- "act3_oscars"
RB_data = left_join(x=RB_data, y=occurences, by=c(director_name = "Var1"))
colnames(RB_data)[52] <- "movie_oscars"
RB_data[c("dir_oscars","act1_oscars","act2_oscars","act3_oscars","movie_oscars")][is.na(RB_data[c("dir_oscars","act1_oscars","act2_oscars","act3_oscars","movie_oscars")])] <- 0
RB_data$actor_oscars = RB_data$act1_oscars + RB_data$act2_oscars + RB_data$act3_oscars
RB_data = RB_data[ , !(names(RB_data) %in% c("act1_oscars","act2_oscars","act3_oscars","genre1","genre2","genre3","genre4","genre5","genre6","genre7"))]

RB_data$movie_title = substr(RB_data$movie_title,1,nchar(RB_data$movie_title)-1)

##Establishing separate datasets for time periods
data11_15 <- filter(.data = RB_data, title_year < 2016)
data16 <- filter(.data = RB_data,title_year == 2016)
```

## Section 1: Introduction

The film industry is expected to generate global box office revenues of almost US\$49.3bn by 2020, from a forecast of US\$38.3bn in 2016[^1], representing a CAGR exceeding 32%. These growth levels will likely see vast resources poured into the industry, in search of the next "big hit". 

Outside of India, the US continues to lead in film production, accounting for an estimated US\$10.7bn in box office revenues in 2016[^2]. Yet in contrast to Indian films, which principally serve a domestic audience, Hollywood films cater for different audiences in different countries, overcoming issues varying from political censorship through to cultural sensitivities, to maximise their appeal and potential commercial success.

```{r, echo=FALSE}

names <- c(2016, 2017, 2018, 2019, 2020)
globalboxoffice16_20 <- c(38.3, 41.2, 44, 46.7, 49.3)
USboxoffice16_20 <- c(10.7, 10.6, 10.9, 11.1, 11.3)
boxoff <- data.frame(names, globalboxoffice16_20, USboxoffice16_20)

year <- c(2016, 2017, 2018, 2019, 2020)
type<- c('global','global','global','global','global')
value <- c(38.3, 41.2, 44, 46.7, 49.3)
global_df <- data.frame(year, type, value)

year <- c(2016, 2017, 2018, 2019, 2020)
type <- c('US','US','US','US','US')                      
value <- c(10.7, 10.6, 10.9, 11.1, 11.3)
US_df <- data.frame(year,type,value)

boxoff <- rbind.data.frame(global_df,US_df)
ggplot(boxoff, aes(x = year, y=value, fill= type))+ geom_bar(stat='identity', position='dodge')+ ggtitle ('Global versus US Box Office Revenues per Year') + theme(plot.title = element_text(hjust=0.5))+ labs(x='Year', y = ' Revenues (in bn$)') 

```

Although continued growth in China and India are likely to dominate global box office revenue growth until 2020, Hollywood is likely to remain a bellweather for judging a film's global success. With that in mind, are there factors that can help predict a film's popularity, and with that, guide future decisions on the types of films produced? In turn, can this better inform investors decisions?

This report shall examine a sample of movie data pulled from IMDB between 2011-16, concentrating on the US film industry. We will evaluate how we should measure popularity, focusing on 2011-15 data, before devising a regression model that can help predict popularity. We will then test its capacity to predict 2016 trends, before noting the limitations of our work, and areas for further development.

As this report shall conclude, we identify the number of IMDB votes per film, and box office revenues as indicators of social popularity and commercial success. Our models indicate that audiences and producers benefit from larger projects, but as we discuss, we encounter several problems owing to shortcomings with available data.


[^1]: Statista (2016) 
[^2]: Statista (2016) 

\pagebreak

## Section 2: Data sampling and cleaning

The data compiled for this project/analysis is obtained from 2 different datasets:   

* **IMDB Movie Dataset**           
* **Oscar Awards Dataset**        

We have cleaned both datasets and compiled them into a single dataset. The object names and cleaning methodology applied is discussed further within Appendix 1 & 2.   

Overall, from an initial sample of 5,044 observations taken between Jan 2011 to Aug 2016, the cleaned movie dataset has 535 observations over 43 variables. Please note that there are 21 variables which are genre indicators, and 4 are occurrence variables (see comment below). We have split our datasets to between 2011-15 for our core analysis, with Jan-Aug 16 data kept to undertake backtesting.   

Given the lack of data on several variables, we have derived an ROI variable based on ticket sales divided by a film's budget, to gauge box office success. We have also derived genre dummies, based on the number of times a particular genre is mentioned for each film, to determine if some films are more popular than others. Finally, in an effort to gauge actor and director popularity, we have derived dummies for the lead, two supporting actors, and director, both based on the number of times they appear within our sample. We have complemented this with separately pulling up Oscar data on both areas, as we recognise audience preferences are likely to change rather slowly over time (e.g. favourite actor, etc).

We discuss the merits of this approach throughout the report, along with commenting about potential limitations and improvements within Section 6.                     
         
\pagebreak

## Section 3: How do we measure a film's popularity?

### What metrics should we use to determine our dependent variable?

Determining what variable should represent popularity, itself a subjective quality, gives rise to several potential proxy variables. These can be divided between those that are financially driven relative to social media metrics, of which we consider each in turn, arriving at five possible variables.

An obvious proxy would be revenues, should we determine this a valid measure of commercial success. Yet a limitation of the data available is we can only track global box-office ticket sales, rather than all associated revenues. This ignores digital sales from streaming, DVD sales, and any other merchandise or commercial agreements (e.g. in-film advertising).

A second issue is whether a low grossing film is still a success, relative to its underlying budget? We condition for this by examining a film's box office return on investment ("ROI"). 

Social media provides us with three relevant metrics. The first surrounds the number of facebook likes a film has received. Although a singular expression of popularity, this may not be entirely accurate, as we do not when this data was collected (e.g. how many days / weeks after the film was released in the US, and how the latter is likely to vary by geography).

The remaining two metrics concern IMDB scores, and the number of votes received. IMDB scores should provide a direct measure of popularity, which we assume are evenly (normally) distributed between 0-10. The number of users may help quantify the depth of support, and potentially represent a further proxy for capturing popularity.

We recognise that social media metrics will be lagged indicators of a film's success. Hence, we are likely to depend upon a commercial variable to project future success, although social media can help by identifying film types that are likely to prove popular, which may form the basis of choosing future films to invest within. 

### Descriptive analysis

We produce boxplots and density graphs of the five variables above, along with budget to provide a sense-check. These can all separately be found in the appendices.

We summarises some of the key descriptive findings of these graphs, along with illustrating the results of our ROI boxplot (limited to returns up to 5.0x) and IMDB density graph:

``` {r, results = "asis", warning=FALSE, message=FALSE, echo=FALSE}
summary_data <- data11_15 %>% select(gross, budget, num_voted_users, imdb_score, movie_facebook_likes, return)
summary_data = as.data.frame(describe(summary_data, quant = c(.25,.75)))
summary_data = summary_data[ , !(names(summary_data) %in% c("vars","n","mad","range","kurtosis","se","trimmed"))]
rownames(summary_data) <- c("Gross Revenue","Budget","Number of voted users","IMDB Score","Movie's Facebook Likes","ROI")
colnames(summary_data) <- c("Mean","Stan. Dev.","Median","Min","Max","Skew","1st Quar","3rd Quar")
numeric_columns <- sapply(summary_data, mode) == 'numeric'
summary_data[numeric_columns] <-  round(summary_data[numeric_columns], 1)
kable(summary_data)

```

```{r, results = "asis", warning=FALSE, echo=FALSE}
imdbden <- ggplot(data=data11_15)+geom_density(aes(x=(imdb_score)))+xlab("Imdb score")+ylab("Density")
roibox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=return)) + ylim(0,5)+ylab("Return/100%")
grid.arrange(imdbden, roibox,  ncol=2)
```

We observe all our variables except IMDB scores are positively skewed, with the latter negatively skewed. This confounds our earlier thoughts on IMDB scores being normally distributed. We will thus need to proceed with any regression analysis carefully (see comments below).

Examining our financial metrics, our ROI has a median return of 1.2x, although this engenders significant volatility, reflected within our wide range. This volatility seems consistent with the level of risk associated with producing films, given the uncertainty in audience receptiveness.

Our last observation is the comparative depth of IMDB votes relative to facebook likes. Although uncertainty remains concerning the collection of this data relative to the timing of a film's release, given the negative skew of IMDB ratings, the higher number of votes may prove a more desirable proxy in gauging popularity. We shall confirm this by testing how these variables correlate with each other, to guide our final choice on our dependent variables. 


### Correlation analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(Hmisc)
cordata <- select(data11_15, imdb_score, 
                  movie_facebook_likes, gross, return, 
                  budget, num_voted_users)
cor_table <- round(cor(cordata),2)
kable(cor_table)

matcordata <- as.matrix(cordata)
pvalcor_table <- rcorr(matcordata, type="pearson")
kable(pvalcor_table$P)

```

The above correlations are all statistically significant, with the exception of our ROI variable, which comes as quite a surprise. It is unclear why there is not a positive relationship relative to some of the social media metrics above. This may potentially suggest the impact of outliers in our sample, which may be reducing any underlying correlation. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
A<- filter(RB_data,return<1)
B<- filter(RB_data, between(return,1,3))
C<- filter(RB_data, return>3)

A1<-select (A, 'num_voted_users','return','gross' )
A1[,"return"] <- "<1"
A2<-select (B, 'num_voted_users', 'return', 'gross')
A2[,"return"] <- "1-3"
A3<-select (C, 'num_voted_users', 'return', 'gross')
A3[,"return"] <- "3>"

final_A <- rbind(A1,A2,A3)
ggplot(data=final_A, aes(x=gross, y=num_voted_users)) +
  geom_point(position="jitter", alpha=0.5) + facet_wrap(~return) + ggtitle('Number of Voted Users based on ROI')+ theme(plot.title = element_text(hjust=0.5))

ggplot(data=final_A, aes(x=RB_data$return, y=gross)) +
  geom_point(position="jitter", alpha=0.5) + xlim(0,5)+ xlab("ROI < 5.0x") + ggtitle('Box office sales vs ROI')+ theme(plot.title = element_text(hjust=0.5))
```

In contrast to revenues, after reviewing the two scatterplots above, we do not consider ROI as a suitable dependent variable. We comment further in section 6, as we'd expect ROI to be a significant factor in measuring success.   

Revenues as a financial metric has demonstrated the positive relationships we expected to see amongst social media (e.g. facebook likes and number of voted users), indicating that expressions of support tend to correspond with higher box office revenues (i.e. people go to the cinema). 

Equally, we observe a more positive correlation between number of IMDB voters, relative to both IMDB scores and facebook likes. This represents a better proxy relative to IMDB scores themselves, with a strong negative skew in IMDB scores suggesting that those voting are likely to be fans conveying their support for a film, rather than providing a balanced critique. 

We believe both revenue and the number of IMDB votes represent suitable dependent variables. Yet both demonstrate strong positive skew, which could bias any parameter estimate, and affect standard errors that determine t-tests. Remedies available include a GLS-based approach, or to transform our variables to resemble a normal distribution. We therefore transform both our revenue and number of votes variables by natural logs raised to the power of 6 and 4 respectively (see below). As these transformations will generate beta estimates which are not intuitive, we conduct our regressions without these adjustment, altering our y-variable at the end to get a better understanding of our parameters and overall adjusted R-squared.

```{r, echo = FALSE}
numden <- ggplot(data=data11_15)+geom_density(aes(x=(num_voted_users)))+xlab("Number of voted users")+ylab("Density")+ggtitle("Density Plots")
revden <- ggplot(data=data11_15)+geom_density(aes(x=(gross)))+xlab("Revenue/$")+ylab("Density")+ggtitle("Density Plots")

numadj <- ggplot(data=data11_15)+geom_density(aes(x=log(num_voted_users)^4))+xlab("Number of voted users/log^4")+ylab("Density")
revadj <- ggplot(data=data11_15)+geom_density(aes(x=log(gross)^6))+xlab("Revenue/log^6")+ylab("Density")

grid.arrange(numden, revden, numadj, revadj, ncol=2)


```


\pagebreak

## Section 4: Regression Analysis

### Social media: Number of IMDB votes

```{r, echo=FALSE, results = "asis"}

log4numvoted_users <- (log(data11_15$num_voted_users)^4)

usereg1 <- lm(data = data11_15, num_voted_users~gross)

usereg2 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence+ actor2_occurence+ actor3_occurence)

usereg3 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence+ director_occurence)

usereg4 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence + movie_oscars + actor_oscars)

usereg5 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence + duration + actor_oscars)

usereg6 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence + duration + actor_oscars + actiondummy + adventuredummy + comedydummy +
                familydummy + fantasydummy+horrordummy+romancedummy + scifidummy+thrillerdummy)

usereg7 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence + duration + actor_oscars + actiondummy + familydummy + romancedummy +
                scifidummy + thrillerdummy)

usereg8 <- lm(data = data11_15, num_voted_users ~ gross +actor1_occurence + duration + actor_oscars + familydummy + scifidummy )

usereg9 <- lm(data = data11_15, num_voted_users ~ gross + actor_oscars + familydummy + scifidummy)

usereg10 <- lm(data = data11_15, log4numvoted_users ~ gross + actor_oscars + familydummy + scifidummy)




stargazer(usereg1, usereg2, usereg3, usereg4, usereg5, usereg6, usereg7, usereg8, usereg9, usereg10, type = "html", report = "vct*", font.size = 'tiny')

log4numvoted_users1 <- (log(data11_15$num_voted_users)^4)
Usereg11 <- lm(data = data11_15, log4numvoted_users1 ~ gross + actor_oscars + familydummy + scifidummy)
#log4numvoted_users2 <- (log(data16$num_voted_users)^4)
#Usereg12 <- lm(data = data16, log4numvoted_users2 ~ gross + actor_oscars + familydummy + scifidummy)

#stargazer(Usereg11, Usereg12, type = 'html',report = "vct*")

```

We start with a simple regression against box office revenues to gauge whether a film's cinema success (in purely absolute terms) corresponds with increased IMDB activity. We do not consider budget or ROI as an independent variable, given the former's high correlation (and thus introducing the risk of multi-collinearity), and the latter's minimal correlation coefficient. 

Our initial results (equation 1) indicate an additional IMDB vote is cast for every US\$1,000 in ticket sales, that is statistically significant at a 5% confidence interval (we assume all t-tests are two-tailed). An adjusted ${R}^{2}$ of 0.435 is generated, providing a benchmark that can be refined further, given the size of our residual standard error ("RSE").

We first examine the impact of featured actors and director (equations 2-4). This counts the number of occurrences within our sample only, and does not consider other films within the period. Notwithstanding, this may help reduce any serial correlation within our error term (i.e. an actor favoured in the past is likely to remain favoured at present). We also appraise the number of Oscars each actor and director has been awarded, to further reduce serial correlation. This also introduces error, as it counts any award and applies it retrospectively across our sample, although we believe this is acceptable, with actor reputations forged over many years prior to an award.

From our results, only the 1st actor appears statistically significant, with a negligible impact on increasing our adjusted ${R}^{2}$. We find actor Oscars is stastically significant, contributing an extra 61,000 votes per Oscar, with movie Oscars insignificant. The latter is likely attributable to an extended lag between a film being released and the subsequent award ceremony held.

Our next step examines if long films (i.e. > 150mins) affect audience sentiment. Although expecting this to be negligible, this proved materially significant, increasing our adjusted ${R}^{2}$ to 0.559, whilst rendering our Actor 1 variable insignificant. There is no apparent reason for this. An investigation of the scatterplot below would suggest outliers may be influencing these results. We remove this variable upon commencing our later refinement of our model within equations 8-10, as without any likely proxy, this appears to represent a spurious result.

```{r, echo=FALSE, warning=FALSE}
ggplot(data11_15, aes(x = duration, y = num_voted_users)) + geom_point() + ggtitle("Duration vs Number of Voted Users") + ylab("Number of Voted Users")
```

The final criteria we consider is film genre. This is not straightforward, as a film can belong to more than one category (e.g. a sci-fi, action thriller). We adopt a count-based approach, based on the number of times a description appears, although this may introduce an added source of multicollinearity, which we attempt to limit by being selective over the categories included. 

We subsequently notice that both family and sci-fi dummy genres are statistically significant. Bizarrely, we generate a negative coefficient for family films, implying these are likely to receive 79,000 less votes. Given the selection bias likely apparent with IMDB data, this may reflect the age characteristics of those voting. 

We observe that Action, Romance, and Thriller dummies remain insignificant; inconjunction with our lead actor variable, these are subsequently dropped. This also applies to our duration variable, leading to equation 9. We recognise this is still conditioned on a skewed dependent variable, so equation 10 implements the ${\log {x}}^{4}$ transformation noted above. This results in an adjusted ${R}^{2}$ of 0.443, whilst applying a ${x}^{\frac{1}{4}}$ adjustment to our parameter, before multiplying by 100, provides the percentage impact on y. We can see that a US$1 of revenue will raise IMDB votes by 8%, whilst there are > 500+% increases in votes should a participating actor hold an Oscar, or the film be sci-fi orietated. The negative coefficient for family movies, if considered in absolute terms, would entail a significant decrease in votes. 

Overall, this model should mitigate the effect of statistical bias affecting our standard errors, and is intended to attain specification efficiency. However, it is likely this model violates our independently and identically distribution ("iid") assumptions on our error terms, which is likely to be affected by an omitted variable(s). The high t-value attained on our intercept coefficient may also suggest  this. We discuss overall model robustness further in section 5.


### Commercial: Box office ticket sales


```{r, results = "asis", echo = FALSE}

log6_gross <- (log(data11_15$gross)^6)

rev_mod1 <- lm(data=data11_15, gross ~ (budget))
rev_mod2 <- lm(data=data11_15, gross ~ (budget + actiondummy + adventuredummy + comedydummy +
                familydummy + fantasydummy+horrordummy+romancedummy + scifidummy+thrillerdummy))
rev_mod3 <- lm(data=data11_15, gross ~ budget + actiondummy + scifidummy + comedydummy + actor_oscars + dir_oscars + movie_oscars)
rev_mod4 <- lm(data=data11_15, gross ~ (budget + actiondummy + scifidummy + comedydummy + director_occurence + actor1_occurence + actor2_occurence + actor3_occurence))
rev_mod5 <- lm(data=data11_15, gross ~ (budget + actiondummy + scifidummy + comedydummy + director_occurence + actor2_occurence + actor3_occurence))

rev_mod6 <- lm(data=data11_15, log6_gross ~ (budget + actiondummy + scifidummy + comedydummy + director_occurence + actor2_occurence + actor3_occurence))
rev_mod7 <- lm(data=data11_15, log6_gross ~ (budget + actiondummy + comedydummy  + director_occurence + actor2_occurence))


stargazer(rev_mod1, rev_mod2, rev_mod3, rev_mod4, rev_mod5, rev_mod6, rev_mod7, type = "html", report = "vct*", font.size = 'tiny')

```

We follow a similar methodology above to translate social popularity into revenue generation by examining the impact of genres, actors, and budget. Contrary to the above, which reflects popularity on lagged variables, this model is intended to help hypothesise on future revenue performance.

We notice a discrepancy in film genres, with action and comedy films having a significant impact on revenues, the former having a negative effect. This may reflect the extra costs associated with stunts and special FX, which may not entirely be recouped from box office sales alone.

Our final model (equation 7) eliminates any insignificant variables, whilst also suggesting that the number of director and lead supporting actor appearances may be significant. We receive this cautiously, given the issues with actor variables mentioned above when appraising social metrics. We further observe this classification of lead and supporting actor may be subjective; one film in the Batman franchise (the "Dark Knight") cites Christian Bale as Actor 2 despite playing the lead role of Batman. We suspect other instances, and thus consider this a more general measure of audience interest in participating actors. 

We note a slight improvement in adjusted ${R}^{2}$ of 0.482 relative to equation 6. This benefits from a slight improvement in degrees of freedom, whilst equation 6 illustrates the impact of bias prior to adjusting our y-variable, given the change in significance and co-efficient sign on some variables (e.g. sci-fi dummy; actor 3 occurrence). 


\pagebreak

## Section 5: Robustness and Hypothesis Tests

### Robustness

Prior to backtesting our models, we want to get a sense of overall model robustness. We examine residual plots of our final models to help determine whether our iid assumptions on our error term are valid:


```{r, echo=FALSE, align="center", warning=FALSE, message=FALSE, results='hide'}
residualPlot(usereg10) + title("Social Popularity model : Residual v/s Fitted values ") # residual plot for our social media model (with the log)
residualPlot(rev_mod7) + title("Commercial Success model : Residual v/s Fitted values") # residual plot for our commercial model (with the log)
```

The trend line on both graphs indicates our iid assumptions are violated, with serial correlation present. This is likely attributable to other variables being omitted, along with potential error within some of our variable estimates. We would validate this with a Durbin-Watson test, although the residual plot is relatively self-evident.

We expect this to affect the accuracy of our standard error (and thus our t-values), increasing the likelihood of Type I and II errors. For the hypothesis tests that follow, we therefore must apply caution to any final result.

### Hypothesis tests

We start by regressing our 2011-15 model on our Jan-Aug 2016 dataset. This includes 37 data-points. With our log-transformed equations consistent with a normal distribution, we assume that a sample of this size should satisfy the central-limit theorem (ie. a sample > 30), enabling meaningful analysis; although we recognise further data-points would provide further comfort.

We obtain the following results for our IMDB votes and Revenue regressions:

```{r, echo=FALSE, results="asis"}
#Stargazer with side by side comparison of these two equations between 2011-15 and 2016
log4numvoted_users <- (log(data16$num_voted_users)^4)
usereg11 <- lm(data = data16, log4numvoted_users ~ gross + actor_oscars + familydummy + scifidummy)

log6_gross <- (log(data16$gross)^6)
rev_mod8 <- lm(data=data16, log6_gross ~ budget + actiondummy +comedydummy +director_occurence+ actor2_occurence)

stargazer(usereg10, usereg11, rev_mod7, rev_mod8, type = 'html',report = "vct*", font.size = 'tiny')

```

Nominally, our social metric model suggests a good fit with 2016 data, based on a high ${R}^{2}$ being attained. Our 2016 revenue model implies a poorer fit. Combined with low t-values generally being observed (with the exception of revenue and budget variables in our social media and revenue regressions respectively), this would normally be a symptom of multi-collinearity, notwithstanding our efforts to achieve the contrary. We give our models the benefit of the doubt, however we recognise the potential for this to seriously undermine any resulting conclusion. These models also suggest omitted variable bias, with potential symptoms including a high t-value for our constant (social metric model), and relatively low adjusted ${R}^{2}$ (revenue model).

We perform an F-test to contrast the variance between our 2011-15 and 2016 models. Should these variances be similar, enabling the rejection of $H_1$ this would indicate our 2011-15 model may represent a reasonable fit on 2016 data. Formalising our hypothesis:

$$H_0 : \frac{\sigma^2_{16}}{\sigma^2_{11-15}} = 1$$
$$H_1 : \frac{\sigma^2_{16}}{\sigma^2_{11-15}} \neq 1$$

```{r, echo=FALSE} 
var.test(usereg10, usereg11) # F-test for social popularity
var.test(rev_mod7, rev_mod8)# F-test for commecial popularity

```

We can apparently reject our null hypothesis for our social media model, and the alternate hypothesis for our revenue model, at a 5% confidence interval. Given the potential issues we have identified above, it would not seem unreasonable to reject both null hypothesis. However, the p-values are not decisive for either F-test (0.01 for social media, and 0.18 for revenues), highlighting the prospect of both Type I and II errors respectively. 

We separately examine what our parameter coefficients return across both models, to appraise any variation between these models. We formulate our hypothesis as follows:

$$H_0 : \beta_{(i\ , \ 11-15)} = \beta_{(i\ ,\ 16)} \  \ \ or \  \ \ \  \beta_{(i\ ,\ 11-15)} - \beta_{(i\ ,\ 16)} = 0$$
$$H_1 : \beta_{(i\ , \ 11-15)} \neq \beta_{(i\ ,\ 16)} \  \ \ or \  \ \ \  \beta_{(i\ ,\ 11-15)} - \beta_{(i\ ,\ 16)} \neq 0$$
                    

```{r, echo=FALSE, results="asis"}

#Z Test Results Tables

name<- c('gross', 'actor_oscars', 'familydummy', 'scifidummy')
z_statistics<- c(0.3610,2.8410,-2.3950,-1.1791)
p_value<-c(0.7188,0.046,0.0168,0.238)
ztable<- data.frame(name,z_statistics, p_value)
kable(ztable, caption = "Z Test for co-efficient for Social Popularity Model")
```


```{r, echo=FALSE, results="asis"}
name<- c('budget', 'actiondummy', 'comedydummy', 'director_occurence', 'actor2_occurence')
z_statistics<- c(0.7918,-5.7540,-0.1851,1.5601,2.5086)
p_value<-c(0.4296,0,0.8572,0.1188,0.012)

ztable2<- data.frame(name,z_statistics, p_value)
kable(ztable2, caption = "Z Test for co-efficient for Commercial Success Model")
```

What appears evident is both our box office figures (within our social metric model), and budget (within our revenue model) result in rejecting our alternate hypothesis. Despite our standard errors potentially being inaccurate, these variables appear to be credible in influencing these models, premised on their significant contribution to ${R}^{2}$ and consistently generating significant t-values. Yet without more complete data, it is still conceivable they do not reflect underlying causality (i.e. a third variable may be a factor).

Our film genre produce variable results, with sci-fi and comedy film estimators rejecting their alternate hypothesis for 2016. Although suggestive of predictive capability, the inconsistency between these models, coupled with our concern over modelling error, would raise doubt on if these can be relied upon.

### What does this all mean?

Putting aside concerns on model robustness, our results suggest that popularity is a function of how "big" the film is expected to be, based on box-office revenues generated. This is consistent with our revenue model, which points to a larger budget helping to generate higher revenues. This perhaps shouldn't come as a surprise: larger budgets result in better known actors, and an increased marketing presence, appealing to both the loyalty of fans and raising the film's wider profile.

The volatility we saw within our descriptive statistics is partly echoed within our regression models, given the lack of an apparent "ready formula" in targeting either specific genres, actor / director appearance frequency, or the impact of awards in influencing audience reviews or wider ticket sales. This was most evident when contrasting the genres affecting popularity (family; sci-fi) relative to revenues (action; comedy).

Realistically, the effectiveness of our analysis has been hindered by the overall quality of data available, and the shortcomings of proxies used to estimate specific characteristics (e.g. actor / supporting actor popularity). We discuss this further in our Limitations section below.


\pagebreak

## Section 6: Limitations

Besides the commentary above on robustness, we recognise there are several issues within our data. The original sample, though randomly generated, does not facilitate a more comprehensive assessment of Hollywood and non-Hollywood film statistics over the time horizon. It may also have resulted in the skewness observed within our datasets. 

Being unable to source separate details on financial characteristics on each film has further hindered this process, whilst limiting our ability to investigate the full value chain. Examples of other financial characteristics we wanted to appraise include:

* A breakdown of budget expenses - marketing: understanding spend to promote films prior to release, and upon the immediate release of a film. This includes the amount spent on social media platforms, relative to conventional mediums (e.g. newspaper ads; TV commercials, etc), to better understand how this affects the perception of popularity and contributes to revenues

* A breakdown of budget expenses - pre / post production costs: including salaries for the leading actor(s) / supporting actors. This would better approximate the value of an actor, including their perception of popularity, representing a more apt variable relative to counting the number of actor occurences between 2011-16 (see below).

* DVD, in-film advertising, merchandise sales, and any cash subsidies: To gauge financial success, understanding the contribution of other revenue streams to determining overall pre-tax returns on investment. This also applies to any direct government incentives (e.g. subsidies) to support the production of films. This data is likely to boost the significance of our ROI estimator.

We also recognise that our attempts to quantify film-specific estimators could be further improved. Qualifying the popularity of actors by virtue of their appearance within our random sample alone is insufficient (relative to their overall appearances as a lead or supporting actor). This was partly mitigated by number of Oscars, although left a sufficient gap between well known actors and those that have yet to receive an award. Accounting for this may have reduced the level of serial correlation evident within our residual plots, with film preferences unlikely to be independent between each year (e.g. a favoured actor in one year is likely to remain so in the following period).

Another limitation was our inability to specify a single genre for each film. Our dataset classified each film across multiple genres, resulting in our dummy variables potentially lacking in sufficient power from diluting their relevance. It was thus a surprise to learn that family films were statistically more significant than action, comedy, romance, or thrillers, which were all well represented within our sample. We may thus have introduced error into our residual, which we would seek to correct in future from either a third party classification source, and / or from performing key-word count searches on film synopses. 


\pagebreak

## Section 7: Conclusions and next steps

We conclude that both IMDB votes and revenues are suitable metrics to gauge popularity and likelihood of commercial success. Our initial findings suggest both respond positively to scale - "bigger films" seem to generate a far greater interest and following amongst an audience.

However, owing to data limitations, our regression models have been limited in their predictive capabilities, due to wider concerns over serial correlation, omitted variables, and the prospect of multicollinearity. This has made it difficult to judge the outcomes of our hypothesis tests, with our categories each responding differently to types of film genre, and the seeming popularity of actors and directors. 

In terms of developing our study, we would like to understand how these findings apply within other markets, and if patterns observed for Hollywood, remain applicable elsewhere (e.g. China, India, Western Europe).



\pagebreak

## Appendix
                          
### Appendix 1 - Source of dataset 

The raw dataset comes from Kaggle website[^1], the Dataset section. The steps the data set was acquired are as follows:

* **Step 1:** Generate a JSON file including a list of 5,000 movie titles and budgets from The Numbers website[^2]. The budgets of scraped movies, as the index value that is used to extract movie title, are ranged from over US\$ 425,000,000 to only US\$ 800,000 which ensures the dataset covers the most mainstream movies in the market.
* **Step 2:** Use the movie title in the JSON file to search from IMDB website for the real IMDB movie links and create a JSON file containing movie-link pairs.
* **Step 3:** Send HTTP request to each specific movie page with the movie-link pairs, and scrape 5,000+ IMDB movie information.
* **Step 4:** Parse and clean the aggregated data, convert into valid format and generate the final CSV table.

Please note that due to the restriction on IMDB website, all the facebook likes data were scraped directly from the Facebook website[^3] in August 2016.

The Kaggle website made some minor changes in October 2017 with the opensource dataset per a DMCA takedown request from IMDB, however, all the data our analysis based on are the original IMDB data. The removed columns are: 


```{r results = "asis", echo = FALSE}
library(knitr)
#library(stargazer)
#library(xtable)
#options(xtable.floating = FALSE)
#options(xtable.timestamp = "")

Variable_No <- c(1:13)

Variables <- c("actor_1_facebook_likes",
               "actor_2_facebook_likes",
               "actor_3_facebook_likes",
               "aspect_ratio",
               "cast_total_facebook_likes",
               "color",
               "content_rating",
               "director_facebook_likes",
               "facenumber_in_poster",
               "movie_facebook_likes",
               "movie_imdb_link",
               "num_critic_for_reviews",
               "num_user_for_reviews")
variable_table <- data.frame(Variable_No, Variables)

kable(variable_table, caption = "Variables", align = c('c', 'l'))

```


[^1]: Kaggle: <https://www.kaggle.com/tmdb/tmdb-movie-metadata>. 
[^2]: The Number: <http://www.the-numbers.com/movie/budgets/all>.
[^3]: Facebook: <https://www.facebook.com/>.
\pagebreak

### Appendix 2 - Data Cleaning Methodology

         
1. **IMDB Movie Dataset:** The raw dataset is the IMDB information about the movies released between 1916 and 2016 (August), scrapted by Kaggle user chuansun76 from IMDB website. It contains 28 variables and 5043 observations. These variables include information about the movie performance on the box office, the actor(s) name, direcor(s) names, movie genre, movie facebook likes and more. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


  * **Step 1 - Cleaning up inconsistent observations:** The raw dataset contained a lot of inconsistencies, namely 'NA' or Blank values for several observations. In order to obtain a consistent data to perform analysis on, we **_removed all the observations with any NA or blank values_**.                
  * **Step 2 - Removing duplicate values:** We observed that the dataset contained duplicate observations, which were also removed.
  * **Step 3 - Limiting dataset by time frame and country:** The money-related variables in the dataset would be influenced by inflation, and the consistency of social presence variables is heavily reliant to the social media popularity. Therefore, it is reasonable to **_narrow down the dataset timeframe into 2011 - 2016 (August)_**. Besides, there are certain limit[^1] on the types of box office currency, so we only **_focus on US movie market_** to avoid the influence of exchange rate fluctuation.
  * **Step 4 - Segregating the movie genres:** The dataset contained the movie genres in the form of a single string, with every genre of the movie, delimited by a '|' symbol. In order to get the actual genres separated and ready to use, we used created flags in order to check whether the movie is of a particular genre. For example: the 'action_genre' column will have a 1 value for an observation, if it is an action movie.
  * **Step 5 - Calculating the number of occurences of each actor/director:** Another interesting variable that we expect to be of significance to our analysis was the number of times an actor/director has showed up in our dataset. That data would allow us to possibly find interesting points on how an actor/director can impact a movie's performance/success. Thus, we added variables/columns with the **_number of occurences for actors and directors_**.
  * **Step 6 - Calculating the movie ROI:** We add another variable, 'movie_roi' which contains the **_return on investment for each movie_**. This will help us in our analysis.
  * **Step 7 - Selecting only the required columns:** The raw dataset consisted of 28 variables, many of which are not required in our analyses. Thus, we remove the unwanted columns and keep only the data that is specific to our analysis. In the process we reduce the size of the dataset leading to better performance. For more details please see data description below.
    
After deleting the variables that have N/A values and that are less relevant to the aim of our report, our final variables (in alphabetical order) are:

```{r results = "asis", echo = FALSE}
Variable_name <- c("actor_1_name", 
                   "actor_2_name", 
                   "actor_3_name",
                   "actor1_occurence",
                   "actor2_occurence",
                   "actor3_occurence",
                   "actor_oscars",
                   "budget",  
                   "director_name",
                   "director_occurence",
                   "dir_oscars",
                   "genre dummy variables",
                   "duration",  
                   "genres", 
                   "gross",
                   "imdb_score", 
                   "movie_facebook_likes",
                   "movie_oscars",
                   "movie_title", 
                   "num_critic_for_reviews",
                   "num_user_for_reviews", 
                   "num_voted_users",
                   "return/movie_roi",
                   "sum_actor_occurence",
                   "title_year")

Explanation <- c("Main actor/actress 1.", 
                 "Main actor/actress 2.", 
                 "Main actor/actress 3.",
                 "The number of actor/actress 1's occurence in the dataset.",
                 "The number of actor/actress 2's occurence in the dataset.",
                 "The number of actor/actress 3's occurence in the dataset.",
                 "The sum of the Oscar Award all actor/actress have earned.",
                 "Total budget for the movie in US dollar. Some numbers are estimated; they are based on media reports and are often supplied by sources close to the production.", 
                 "Main director's name.",
                 "The number of the main director's occurence in the dataset.",
                 "The sum of the Oscar Award main director has earned so far.",
                 "The dummy variables of the movie's genre. 1 stands for the movie belongs to this genre. The dummies include: actiondummy, adventuredummy, animationdummy, biographydummy, comedydummy, crimedummy, documentarydummy, dramadummy, familydummy, fantasydummy, historydummy, horrordummy, musicaldummy, mysterydummy, newsdummy, romancedummy, scifidummy, sportdummy, thrillerdummy, wardummy, westerndummy",
                 "Length of the movie.", 
                 "Genres of the movie. The movie could be multi-genres. ", 
                 "Gross box office earnings of the movie in US dollar.",  
                 "IMDB average score (out of 10).", 
                 "Total likes of the movie's facebook page (up to Aug 2016).",
                 "The sum of the Oscard Award this movie has earned so far.",
                 "Movie's title.",  
                 "Number of critics who wrote reviews for the movie.",  
                 "Number of IMDB users who wrote reviews for the movie.",
                 "Number of IMDB users who voted for the movie rating.",
                 "Gross divided by budget, rounded to 2 decimal places.",
                 "The sum of all actor/actress occurence in the dataset.",
                 "The year the movie released.")
variable_table <- data.frame(Variable_name, Explanation)

kable(variable_table, caption = "Variables")


```

The cleaned movie dataset now has 535 obseravations over 39 variables. Please note that there are 21 variables which are genre indicators, and 4 are occurence variables.                          
                                   
                                                        
2. **Oscar winners dataset:** The raw dataset of awards contained 2321 observations over 4 variables. This database consisted the nominees and winners of the Academy Awards (or Oscars) ever since its inception, i.e. from 1927 to 2015.     
  * **Step 1 - Cleaning up inconsistent observations:** The raw dataset contains some inconsistent observations where the names of the winner and the film were placed in the incorrect column. Since this was the case for the initial few records only, we ignored this and copied the values in the 'film' column to the 'names' column.                
  * **Step 2 - Limiting dataset:** The dataset included both nominess and winner from every category. We were interested in collecting data about the actors, directors, and the best picture winners only in order to see how that impacts the success of a movie. Therefore, we **_excluded the nomiees and only kept the winners for the awards_** related to Best Actor/Actress in a Lead/Supporting role, Best Director and Best Picutre.
  * **Step 3 - Counting the awards:** In order to get the data of the number of wins for each individual, we introduced a new column 'num_wins' which counted the **_number of occurences of a name in the winners list_**. Using this data makes sense as in order to assess the impact of this on a movies popularity/success.
  * **Step 4 - Selecting the required columns:** The raw dataset contains 4 variables, and a count column, out of which only the 'count' and 'name' column is required for our analysis. Thus we select only a small subset of the raw data for our analysis.                   

The cleaned awards data now has 434 observations over 2 variables. This data will come handy to check which movies/actors/directors have oscar(s) to their name(s) and how that impacts the success of a movie.


3. **Final (Cumulative) Dataset:** In order to get the final working database, we combine the information from the two cleaned datasets.             
  * **Step 1 - Summarizing the datasets:** We need to get the number of award wins for actors, directors, and movie for each observation in the into the IMDB movie dataset, from the 'Oscar winners dataset'. We do this by introducing new variables that capture **_the count of oscars for each actor, director, and movie for each observation_**.
  * **Step 2 - Dividing the final data into two datasets:** The aim of our analysis is to create a model that can predict the success of a hollywood movie. To achieve that, we will build a regression model using the data of movies from 2011 to 2015 and then test the consistency of the data for the movies in 2016. This will provide a clear indication of how our model fits with current movies, and a direction of further development. Thus we **_create two subsets of the final data, one for data of movies from 2011 to 2015 and the other with the data of movies for 2016_**.   

[^1]: Please see the limitation part and Appendix 1 for more information about the raw data limitation.


### Appendix 3 - Boxplots and Density graphs

```{r, echo =FALSE, warning=FALSE, message=FALSE}
#density plots


imdbden <- ggplot(data=data11_15)+geom_density(aes(x=(imdb_score)))

fbden <- ggplot(data=data11_15)+geom_density(aes(x=movie_facebook_likes))

revden <- ggplot(data=data11_15)+geom_density(aes(x=gross))

roiden <- ggplot(data=data11_15)+geom_density(aes(x=return))

budden <- ggplot(data=data11_15)+geom_density(aes(x=budget))

numuserden <- ggplot(data=data11_15)+geom_density(aes(x=num_voted_users))

grid.arrange(imdbden, fbden, revden, roiden, budden, numuserden, ncol=2)

#boxplots

imdbbox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=imdb_score))

fbbox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=movie_facebook_likes)) + ylim(0,100000)

revbox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=gross))

roibox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=return)) + ylim(0,5)

budbox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=budget))

numuserbox <- ggplot(data=data11_15)+geom_boxplot(aes(x=1, y=num_voted_users)) + ylim(0,500000)

grid.arrange(imdbbox, fbbox, revbox, roibox, budbox, numuserbox, ncol=2)


```
\pagebreak

## Bibliography and references

We have made reference to various forums on coding best-practices, notably including Stackoverflow.com, and other relevant sources of R studio information available online. These have been cited during the main document, where they have been specific to our study, or represent the application of coding practices not within the Maths and Statistics Foundations for Analytics module. We have not referenced general R studio packages applied within this module (e.g. dplyr; stargazer; etc). 

  Hlavac, Marek (2015). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version
  5.2. http://CRAN.R-project.org/package=stargazer
  
  John Fox and Sanford Weisberg (2011). An {R} Companion to Applied Regression, Second Edition. Thousand Oaks
  CA: Sage. URL: http://socserv.socsci.mcmaster.ca/jfox/Books/Companion
  
  Hadley Wickham, Romain Francois, Lionel Henry and Kirill Mller (2017). dplyr: A Grammar of Data
  Manipulation. R package version 0.7.4. https://CRAN.R-project.org/package=dplyr
  
  Hadley Wickham, Jim Hester and Romain Francois (2017). readr: Read Rectangular Text Data. R package version
  1.1.1. https://CRAN.R-project.org/package=readr
  
  Hadley Wickham and Lionel Henry (2017). tidyr: Easily Tidy Data with 'spread()' and 'gather()' Functions. R
  package version 0.7.1. https://CRAN.R-project.org/package=tidyr
  
  Stefan Milton Bache and Hadley Wickham (2014). magrittr: A Forward-Pipe Operator for R. R package version
  1.5. https://CRAN.R-project.org/package=magrittr
  
  Hadley Wickham (2017). stringr: Simple, Consistent Wrappers for Common String Operations. R package version
  1.2.0. https://CRAN.R-project.org/package=stringr
  
  H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009.
  
  Yihui Xie (2017). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version
  1.17.
  
  Baptiste Auguie (2017). gridExtra: Miscellaneous Functions for "Grid" Graphics. R package version 2.3.
  https://CRAN.R-project.org/package=gridExtra
  
  Revelle, W. (2017) psych: Procedures for Personality and Psychological Research, Northwestern University,
  Evanston, Illinois, USA, https://CRAN.R-project.org/package=psych Version = 1.7.8.


We obtained the original dataset, in conjunction with information on Oscar academy awards, from the following websites: 
<https://www.kaggle.com/tmdb/tmdb-movie-metadata/data>
<https://www.kaggle.com/theacademy/academy-awards>

In terms of documents we have referenced:

[1-2] "Film industry in the US", Statista, Dossier (2016) <https://www.statista.com/study/11472/film-industry-in-the-united-states-statista-dossier/>
[4] "How to tell the greatness of a movie before it is released in cinema", NYC Data Science Academy, Chuansun76 (2016) <https://chuansun76.com/2016/09/23/how-to-tell-the-greatness-of-a-movie-before-it-is-released-in-cinema/>


\pagebreak