{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analytics Homework 2 - Programming 1\n",
    "\n",
    "Group G: Joanna Andari, Karim Awad, Jiye Ren, Nirbhay Sharma, Qiuyue Zhang, Xiaoyan Zhou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (5 points) (You will get the data for this on 25 Nov 2017 8PM): The data collected will invariably be fraught with problems. We proceed nevertheless. Use built-in functions in NetworkX on the data HW2_ who_talks_to_whom.txt to do an organizational network analysis report (1 page max)---essentially calculating centrality measures (try at least one eigenvalue based one) and clustering coefficients and gaining some insight into the network. The objective for me (your client) is to identify who are the leaders and opinion-makers in your cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook only contains the code that produces the elements (Graph, numbers, etc) included in the final report; for more detailed analysis please see the Network_Analytics_HW2_Programming_1_code_full.py file.\n",
    "\n",
    "Several explanations for the following code:\n",
    "1. As explained in the report, the raw data “Sent” and “Received” matrix are very similar - the number of conversation started by each side in a pair are quite balanced, which limited the information we could read from an unbalanced directed network. Thus we only use the averaged conversation data to analyse the social network as there is a length limit;\n",
    "2. The graphs generated each time will be slightly different as we did not set random seeds for the layout. However the other characeristics will stay the same;\n",
    "3. Some functions we used only works properly (as the way we use it in the following code) in some Python 3.X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import collections\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 1: Data Cleaning & Drawing\n",
    "\n",
    "avg_mat = pd.read_csv('./HW2_who_talks_to_whom_avg.csv')\n",
    "\n",
    "# create node list\n",
    "node_no_dict = {i:str(i+1) for i in list(range(81))}\n",
    "\n",
    "avg_node_list = list()\n",
    "for i in list(range(81)):\n",
    "    for j in list(range(81)):\n",
    "        if avg_mat.iloc[i, j] != 0:\n",
    "            avg_node_list.append([node_no_dict[i], node_no_dict[j], avg_mat.iloc[i, j]])\n",
    "\n",
    "# create DiGraph\n",
    "G_total = nx.DiGraph()\n",
    "G_total.add_weighted_edges_from(avg_node_list)\n",
    "\n",
    "# draw the graphs\n",
    "# total (weight > k)\n",
    "k_total = 0\n",
    "\n",
    "node_color_vec_total = dict()\n",
    "for key in G_total.nodes():\n",
    "    if len(G_total.neighbors(key)) >= np.percentile([len(G_total.neighbors(i)) for i in G_total.nodes()], 90):\n",
    "        node_color_vec_total[key] = 'r'\n",
    "    elif len(G_total.neighbors(key)) >= np.percentile([len(G_total.neighbors(i)) for i in G_total.nodes()], 75):\n",
    "        node_color_vec_total[key] = 'hotpink'\n",
    "    else:\n",
    "        node_color_vec_total[key] = 'pink'\n",
    "\n",
    "data_total = {'edgelist': [avg_node_list[i] for i in list(range(2057))],\n",
    "              'tail': [avg_node_list[i][0] for i in list(range(2057))],\n",
    "              'head': [avg_node_list[i][1] for i in list(range(2057))],\n",
    "              'weight': [avg_node_list[i][2] for i in list(range(2057))],\n",
    "              'num_neighbor': [len(G_total.neighbors(i[0])) for i in avg_node_list],\n",
    "              'color': [node_color_vec_total[i[0]] for i in avg_node_list]}\n",
    "node_attr_total = DataFrame(data_total)\n",
    "\n",
    "node_attr_total_draw = DataFrame(columns = ['edgelist', 'tail', 'head', 'weight', 'num_neighbor', 'color'])\n",
    "for i in list(range(2057)):\n",
    "    if node_attr_total['weight'][i] > k_total:\n",
    "        node_attr_total_draw = node_attr_total_draw.append(node_attr_total.loc[i], ignore_index=True)\n",
    "\n",
    "nx.draw(G_total, \n",
    "        pos = nx.spring_layout(G_total, k = 0.5, iterations = 85, scale = 900),\n",
    "        # pos = nx.random_layout(G_total),\n",
    "        edgelist = list(node_attr_total_draw['edgelist']),\n",
    "        with_labels = True,\n",
    "        node_size = [(len(G_total.neighbors(i)) - 2) * 35 for i in G_total.nodes()],\n",
    "        node_color = list(node_color_vec_total.values()),\n",
    "        edge_color = 'darkgrey',\n",
    "        width = [float(d['weight'] / 18 ) for (u, v, d) in G_total.edges(data = True)],\n",
    "        alpha = 0.4,\n",
    "        font_size = 9,\n",
    "        arrows = False)\n",
    "plt.title('Total Conversation Network',\n",
    "          fontweight = \"bold\",\n",
    "          fontsize = 18)\n",
    "plt.savefig('Total Conversation Network',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 2: Network Analysis\n",
    "# essentially calculating centrality measures (try at least one eigenvalue based one)\n",
    "# degree centrality measure\n",
    "degree_ctr_total = nx.degree_centrality(G_total)\n",
    "in_degree_ctr_total = nx.in_degree_centrality(G_total)\n",
    "out_degree_ctr_total = nx.out_degree_centrality(G_total)\n",
    "\n",
    "DC_Counter = collections.Counter(degree_ctr_total)\n",
    "\n",
    "# betweenness centrality measure\n",
    "betweenness_nodes_ctr_total = nx.betweenness_centrality(G_total) # for nodes\n",
    "\n",
    "BC_Counter = collections.Counter(betweenness_nodes_ctr_total)\n",
    "\n",
    "# closeness centrality measure\n",
    "closeness_ctr_total = nx.closeness_centrality(G_total)\n",
    "\n",
    "CC_Counter = collections.Counter(closeness_ctr_total)\n",
    "\n",
    "# Local metrics comparison\n",
    "plt.hist([(value - min([value for key, value in DC_Counter.items()])) / (max([value for key, value in DC_Counter.items()]) - min([value for key, value in DC_Counter.items()])) for key, value in DC_Counter.items()], \n",
    "           bins = 40, \n",
    "           color = 'olivedrab',\n",
    "           alpha = 0.4,\n",
    "           histtype = \"stepfilled\",\n",
    "           label = 'Degree')\n",
    "plt.hist([(value - min([value for key, value in BC_Counter.items()])) / (max([value for key, value in BC_Counter.items()]) - min([value for key, value in BC_Counter.items()])) for key, value in BC_Counter.items()], \n",
    "           bins = 40, \n",
    "           color = 'seagreen',\n",
    "           alpha = 0.4,\n",
    "           histtype = \"stepfilled\", \n",
    "           label = 'Betweenness')\n",
    "plt.hist([(value - min([value for key, value in CC_Counter.items()])) / (max([value for key, value in CC_Counter.items()]) - min([value for key, value in CC_Counter.items()])) for key, value in CC_Counter.items()], \n",
    "           bins = 40, \n",
    "           color = 'darkcyan', \n",
    "           alpha = 0.4,\n",
    "           histtype = \"stepfilled\",\n",
    "           label = 'Closeness')\n",
    "plt.title('(Normalised) Local Metrics Distribution',\n",
    "          fontweight=\"bold\",\n",
    "          fontsize = 16)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.savefig('(Normalised) Local Metrics Distribution')\n",
    "\n",
    "# eigenvector centrality measure\n",
    "eigen_ctr_total = nx.eigenvector_centrality(G_total)\n",
    "\n",
    "EC_Counter = collections.Counter(eigen_ctr_total)\n",
    "\n",
    "# pangerank\n",
    "pagerank_total = nx.pagerank(G_total)\n",
    "\n",
    "pgrk_Counter = collections.Counter(pagerank_total)\n",
    "\n",
    "# Global metrics comparison\n",
    "plt.hist([(value - min([value for key, value in EC_Counter.items()])) / (max([value for key, value in EC_Counter.items()]) - min([value for key, value in EC_Counter.items()])) for key, value in EC_Counter.items()], \n",
    "           bins = 40, \n",
    "           color = 'seagreen',\n",
    "           alpha = 0.5,\n",
    "           histtype = \"stepfilled\",\n",
    "           label = 'Eigenvector')\n",
    "plt.hist([(value - min([value for key, value in pgrk_Counter.items()])) / (max([value for key, value in pgrk_Counter.items()]) - min([value for key, value in pgrk_Counter.items()])) for key, value in pgrk_Counter.items()], \n",
    "           bins = 40, \n",
    "           color = 'darkcyan', \n",
    "           alpha = 0.5,\n",
    "           histtype = \"stepfilled\",\n",
    "           label = 'PageRank')\n",
    "plt.title('(Normalised) Global Metrics Distribution', \n",
    "          fontweight = \"bold\",\n",
    "          fontsize = 16)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.savefig('(Normalised) Global Metrics Distribution')\n",
    "\n",
    "\n",
    "# clustering coefficients and gaining some insight into the network.  \n",
    "clustering_coef = nx.clustering(G_total.to_undirected())\n",
    "avg_clustering_coef = nx.average_clustering(G_total.to_undirected())\n",
    "\n",
    "# find cliques\n",
    "cliques_total = list(nx.find_cliques(G_total.to_undirected()))\n",
    "max_cliques = [i for i in cliques_total if len(i) == max([len(i) for i in cliques_total])]\n",
    "\n",
    "# active people in main cliques\n",
    "max_cliques_set = [set(i) for i in max_cliques]\n",
    "ppl_in_all_max_clique = list(reduce(lambda x, y: x.intersection(y), max_cliques_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
