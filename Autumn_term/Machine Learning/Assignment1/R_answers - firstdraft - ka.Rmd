
---
title: "Machine Learning - Assignment 1"
author: "Karim Awad (01446402)"
date: "30 November 2017"
output: html_document
---

####Question 2.a

1. Loading the data
```{r, echo=FALSE}
rm(list=ls())
setwd('C:/Users/karim/Documents/Imperial/Machine Learning/ProblemSets/Assignment1')
ww_data <- read.csv('winequality-white.csv', sep = ";")

```

2. Constructing a binary column

```{r, echo=FALSE}
ww_data[,"good_wine"] <- ifelse(ww_data[,"quality"] >= 6, 1, 0)
ww_data$good_wine <- factor(ww_data$good_wine, levels = c(1,0), labels = c("good_wine", "bad_wine"))

```

3. Split the data into a training, validation, and test data sets and 4. Z-score normalisation

```{r, echo=FALSE}
library(caTools)
library(dplyr)
library(caret)
#shuffling our sample data (formally) and Z-score normalising across the entire dataset
ww_data1 <- ww_data[sample(nrow(ww_data)),]
ww_data1 <- as.data.frame(scale(ww_data1[1:11]))
#Splitting our data into our data sets
set.seed(100)
ww_sep1 <- sample(seq_len(nrow(ww_data1)), size = 0.4*nrow(ww_data1)) #this does shuffle our sample again
ww_training <- ww_data1[ww_sep1,]
ww_remainder <- ww_data1[-ww_sep1,]
head(ww_remainder)

set.seed(100)
ww_sep2 <- sample(seq_len(nrow(ww_remainder)), size = 0.5*nrow(ww_remainder))
ww_validation <- ww_remainder[ww_sep2,]
ww_test <- ww_remainder[-ww_sep2,]

ww_training_label <- ww_training$good_wine
ww_valid_label <- ww_validation$good_wine
ww_test_label <- ww_test$good_wine


```

5.k-Nearest Neighbours for k=1 to 80

```{r, echo=FALSE}
library(class)
library(gmodels)
ww_training_pred <- knn(train = ww_training_z, test = ww_training_z, cl = ww_training_label, k = 80)
CrossTable(x = ww_training_label, y=ww_training_pred, prop.chisq = FALSE)
table_prac <- table(ww_training_pred,ww_training_label)
(table_prac[1, 2] + table_prac[2, 1])/NROW(ww_training_z)

set.seed(101)
d=NULL
k_count = 0
for (i in 1:80){
  k_count <-  k_count+1
  knn_p <- knn(train = ww_training_z, test = ww_training_z, cl = ww_training_label, k = i)
  tbl <- table(knn_p,ww_training_label)
  missclass_err <- (tbl[1, 2] + tbl[2, 1])/NROW(ww_training_z)
  d=rbind(d,data.frame(k_count,missclass_err))
}

print(d)
ggplot(data = d,aes(x=k_count, y=missclass_err))+geom_line()
  
```


6. Evaluating each classifier on the validation set

```{r, echo=FALSE}

ww_valid_pred <- knn(train = ww_training_z, test = ww_validation_z, cl = ww_training_label, k = 80)
CrossTable (x=ww_valid_label, y=ww_valid_pred, prop.chisq = FALSE)

set.seed(101)
e=NULL
k_count_1 = 0
for (i in 1:80){
  k_count_1 <-  k_count_1+1
  knn_q <- knn(train = ww_training_z, test = ww_validation_z, cl = ww_training_label, k = i)
  tbl <- table(knn_q,ww_valid_label)
  misclass_err_1 <- (tbl[1, 2] + tbl[2, 1])/NROW(ww_validation_z)
  e=rbind(e,data.frame(k_count_1,misclass_err_1))
}

print(e)
```

```{r, echo=False}

ww_test_pred <- knn(train = ww_validation_z, test = ww_test_z, cl = ww_valid_label, k = 10)
CrossTable (x=ww_test_label, y=ww_test_pred, prop.chisq = FALSE)

gen_tbl <- table(ww_test_pred,ww_test_label)
ggplot(data=e, aes(x=k_count_1, misclass_err_1))+geom_line()+geom_line(data=d, aes(x=k_count, y=missclass_err))
accuracy <- (tbl[1, 1] + tbl[2, 2])/NROW(ww_validation_z)

```