---
title: "Machine_Learning_gw1_Daisy"
author: "xiaoyan zhou"
date: "2017Äê11ÔÂ29ÈÕ"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

(a) Build a k-Nearest Neighbours classifier in R for ¡°wine_quality-white.csv¡± that:
1. loads the data file;
```{r}
#library(readr)
winequality_white <- read_csv2("~/IC/Machine learning/groupwork 1/winequality-white.csv")
View(winequality_white)
```
2. construct a new binary column ¡°good wine¡± that indicates whether the wine is good
(which we define as having a quality of 6 or higher) or not;

```{r}
winequality_white["good_wine"] = 0

for (i in 1:nrow(winequality_white)){
  if (winequality_white[i, "quality"] >= 6){
    winequality_white[i, "good_wine"] = 1
  }else{
    winequality_white[i,"good_wine"] = 0
  }
}

```


4. normalises the data according to the Z-score transform;
```{r}
#convert chr to num
winequality_white[] <- lapply(winequality_white, function(x) as.numeric(as.character(x)))
#convert class to factor
winequality_white[["good_wine"]] = factor(winequality_white[["good_wine"]],labels = c("0","1"))
# str(winequality_white)

num_ww <- winequality_white
#normalise dataset
winequality_white["fixed acidity"] = scale(winequality_white["fixed acidity"])
winequality_white["volatile acidity"] = scale(winequality_white["volatile acidity"])
winequality_white["citric acid"] = scale(winequality_white["citric acid"])
winequality_white["residual sugar"] = scale(winequality_white["residual sugar"])
winequality_white["chlorides"] = scale(winequality_white["chlorides"])
winequality_white["free sulfur dioxide"] = scale(winequality_white["free sulfur dioxide"])
winequality_white["total sulfur dioxide"] = scale(winequality_white["total sulfur dioxide"])
winequality_white["density"] = scale(winequality_white["density"])
winequality_white$pH = scale(winequality_white$pH)
winequality_white["sulphates"] = scale(winequality_white["sulphates"])
winequality_white["alcohol"] = scale(winequality_white["alcohol"])

#delete the quality column
#library(dplyr)
ww_data <- subset(winequality_white, select = -quality)
ww_predictor <- subset(ww_data, select = -good_wine)
```

3. splits the data set into a training data set (~40%), a validation data set (~30%) and a
test data set (~30%) ¡ª make sure you shuffle the record before the split;

```{r}
#install.packages("caTools")
#library(caTools)
set.seed(22)
split <- sample(1:3,size=nrow(ww_data),replace=TRUE,prob=c(0.4,0.3,0.3))
training <- ww_data[split ==1,]
validation <- ww_data[split ==2,]
testing <- ww_data[split ==3,]

# labels for 3 data set
train_labels <- training[["good_wine"]] #use [[]]to change it into a vector
valid_labels <- validation[["good_wine"]]
test_labels <- testing[["good_wine"]]

str(train_labels)
#eliminate the good_wine column in 3 set
traind <- subset(training, select = -good_wine)
valid <-subset(validation, select = -good_wine)
testd <-subset(testing, select = -good_wine)
```
5. loads and trains the k-Nearest Neighbours classifiers for k = 1, .., 80;

```{r}
#Check if there are missing value
anyNA(ww_data)

#install.packages("class")
#install.packages("gmodels")
#library(gmodels)
#library(class)

#build a dataframe accuracy_k for saving k and the accuracy rate
accuracy_k <- data.frame(k = 1:80, accuracy = rep(0,80))  
for( i in 1:nrow(accuracy_k)){
   knn_i1 <- knn(train =traind, test = valid, cl = train_labels, k = i)
   knn_i2 <- knn(train =traind, test = valid, cl = train_labels, k = i)
   knn_i3 <- knn(train =traind, test = valid, cl = train_labels, k = i)
   mean_a <-(mean(valid_labels == knn_i1)+mean(valid_labels == knn_i2)+mean(valid_labels == knn_i3))/3
   accuracy_k[i, "accuracy"] <- mean_a
 
}


```


6. evaluates each classifier on the validation set and selects the best classifier;
```{r}
#find the optimal k with the largest accuracy rate
accuracy_k_order <- accuracy_k[order(- accuracy_k[ , "accuracy"]), ]
accuracy_k_order[1, ] # the optimal model is the model with k =24, and the mean accuracy after repeating 3 times is 0.734.

knn_24 <- knn(train =traind, test = valid, cl = train_labels, k = 24)
CrossTable( x = valid_labels, y = knn_24, prop.chisp = FALSE)
mean(valid_labels == knn_24)
```


7. predicts the generalisation error using the test data set, as well as outputs the result
in a confusion matrix.

So a total of 1113 out of 1495, or 25.6 percent of masses were incorrectly classified by the k-NN
approach, where the k we chose is 24.

The cell percentages in the table indicate the proportion of values that fall into four
categories. The top-left cell indicates the true negative results. These 228 of 1495 values
are cases where the test_labels was "0" and the k-NN algorithm correctly identified it
as such. The bottom-right cell indicates the true positive results, where the classifier
and the test_labels agree that the good_wine is "1". A total of 885 of
1495 predictions were true positives.


```{r}
predict24 <- knn(train =traind, test = testd, cl = train_labels, k =24)
CrossTable( x = test_labels, y = predict24, prop.chisp = FALSE)
mean(test_labels == predict24)

```


How do you judge whether the classifier is well-suited for the data set?

